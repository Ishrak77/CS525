{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffb799cf-5126-465d-b50d-17c89220c877",
   "metadata": {
    "papermill": {
     "duration": 14425.653128,
     "end_time": "2024-12-08T17:03:02.517969",
     "exception": false,
     "start_time": "2024-12-08T13:02:36.864841",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n",
      "Available GPU devices: []\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Conv2DTranspose, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from skimage.transform import resize\n",
    "import tensorflow.keras.backend as K\n",
    "import datetime\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -------------------------------\n",
    "# 1. Verify GPU Availability\n",
    "# -------------------------------\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "print(\"Available GPU devices:\", tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Define Custom Metrics\n",
    "# -------------------------------\n",
    "def dice_coefficient(y_true, y_pred, smooth=1):\n",
    "    \"\"\"\n",
    "    Calculates the Dice Coefficient.\n",
    "    \"\"\"\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def iou_metric(y_true, y_pred, smooth=1):\n",
    "    \"\"\"\n",
    "    Calculates the Intersection over Union (IoU) metric.\n",
    "    \"\"\"\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    union = K.sum(y_true_f) + K.sum(y_pred_f) - intersection\n",
    "    return (intersection + smooth) / (union + smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "459a169a-5851-4365-b216-ceee99cd714b",
   "metadata": {
    "papermill": {
     "duration": 14425.653128,
     "end_time": "2024-12-08T17:03:02.517969",
     "exception": false,
     "start_time": "2024-12-08T13:02:36.864841",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 3. Define the U-Net Model\n",
    "# -------------------------------\n",
    "def unet_model(input_size=(128, 128, 4)):\n",
    "    \n",
    "    inputs = Input(input_size)\n",
    "\n",
    "    # Encoding path\n",
    "    c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(c1)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "    c2 = Conv2D(128, (3, 3), activation='relu', padding='same')(p1)\n",
    "    c2 = Conv2D(128, (3, 3), activation='relu', padding='same')(c2)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "    c3 = Conv2D(256, (3, 3), activation='relu', padding='same')(p2)\n",
    "    c3 = Conv2D(256, (3, 3), activation='relu', padding='same')(c3)\n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "\n",
    "    c4 = Conv2D(512, (3, 3), activation='relu', padding='same')(p3)\n",
    "    c4 = Conv2D(512, (3, 3), activation='relu', padding='same')(c4)\n",
    "    p4 = MaxPooling2D((2, 2))(c4)\n",
    "\n",
    "    # Bottleneck\n",
    "    c5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(p4)\n",
    "    c5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(c5)\n",
    "\n",
    "    # Decoding path\n",
    "    u6 = Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    c6 = Conv2D(512, (3, 3), activation='relu', padding='same')(u6)\n",
    "    c6 = Conv2D(512, (3, 3), activation='relu', padding='same')(c6)\n",
    "\n",
    "    u7 = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    c7 = Conv2D(256, (3, 3), activation='relu', padding='same')(u7)\n",
    "    c7 = Conv2D(256, (3, 3), activation='relu', padding='same')(c7)\n",
    "\n",
    "    u8 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    c8 = Conv2D(128, (3, 3), activation='relu', padding='same')(u8)\n",
    "    c8 = Conv2D(128, (3, 3), activation='relu', padding='same')(c8)\n",
    "\n",
    "    u9 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c8)\n",
    "    u9 = concatenate([u9, c1])\n",
    "    c9 = Conv2D(64, (3, 3), activation='relu', padding='same')(u9)\n",
    "    c9 = Conv2D(64, (3, 3), activation='relu', padding='same')(c9)\n",
    "\n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88bcc896-917d-47d3-8e91-f91f3b1a3ae8",
   "metadata": {
    "papermill": {
     "duration": 14425.653128,
     "end_time": "2024-12-08T17:03:02.517969",
     "exception": false,
     "start_time": "2024-12-08T13:02:36.864841",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_data(train_files, data_dir, image_dim=(128, 128)):\n",
    "    \"\"\"\n",
    "    Function to load images and masks from HDF5 files.\n",
    "\n",
    "    Parameters:\n",
    "    - train_files: List of file names of the training HDF5 files.\n",
    "    - data_dir: Directory where the HDF5 files are stored.\n",
    "    - image_dim: Desired dimensions of the output images and masks (height, width).\n",
    "\n",
    "    Returns:\n",
    "    - X: Array of image data with shape (batch_size, height, width, channels).\n",
    "    - y: Array of mask data with shape (batch_size, height, width, 1).\n",
    "    \"\"\"\n",
    "    batch_size = len(train_files)\n",
    "\n",
    "    # Initialize empty arrays for images and masks\n",
    "    X = np.empty((batch_size, *image_dim, 4), dtype='float32')  # 4 channels for images\n",
    "    y = np.empty((batch_size, *image_dim, 1), dtype='float32')  # Single-channel masks\n",
    "    \n",
    "    # Loop through each HDF5 file\n",
    "    for i, h5_file in enumerate(train_files):\n",
    "        file_path = os.path.join(data_dir, h5_file)\n",
    "        with h5py.File(file_path, 'r') as hf:\n",
    "            # Check for the correct keys\n",
    "            if 'image' in hf.keys() and 'mask' in hf.keys():\n",
    "                image = hf['image'][:]  # Expected shape: (H, W, 4)\n",
    "                mask = hf['mask'][:]    # Expected shape: (H, W) or (H, W, C)\n",
    "            else:\n",
    "                raise KeyError(f\"Unexpected keys in {h5_file}: {list(hf.keys())}\")\n",
    "\n",
    "            # If mask has multiple channels, convert to single-channel\n",
    "            if mask.ndim > 2:\n",
    "                mask = np.mean(mask, axis=-1)  # Convert RGB to grayscale\n",
    "\n",
    "            # Resize images if necessary\n",
    "            if image.shape[:2] != image_dim:\n",
    "                image = resize(\n",
    "                    image, \n",
    "                    (*image_dim, image.shape[2]), \n",
    "                    preserve_range=True, \n",
    "                    anti_aliasing=True\n",
    "                )\n",
    "\n",
    "            if mask.shape != image_dim:\n",
    "                # Use nearest-neighbor interpolation for masks to preserve labels\n",
    "                mask = resize(\n",
    "                    mask, \n",
    "                    image_dim, \n",
    "                    preserve_range=True, \n",
    "                    order=0, \n",
    "                    anti_aliasing=False\n",
    "                )\n",
    "\n",
    "            # Normalize the image\n",
    "            image_max = np.max(image)\n",
    "            if image_max > 0:\n",
    "                image = image.astype('float32') / image_max\n",
    "            else:\n",
    "                image = image.astype('float32')\n",
    "\n",
    "            # Normalize the mask\n",
    "            mask_max = np.max(mask)\n",
    "            if mask_max > 0:\n",
    "                mask = mask.astype('float32') / mask_max\n",
    "            else:\n",
    "                mask = mask.astype('float32')  # All zeros\n",
    "\n",
    "            # Assign to batch arrays\n",
    "            X[i] = image  # Shape: (128, 128, 4)\n",
    "            y[i] = np.expand_dims(mask, axis=-1)  # Shape: (128, 128, 1)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "858cfea8-21df-4f66-931b-24364e7d70f7",
   "metadata": {
    "papermill": {
     "duration": 14425.653128,
     "end_time": "2024-12-08T17:03:02.517969",
     "exception": false,
     "start_time": "2024-12-08T13:02:36.864841",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 62\n",
      "Training samples: 49\n",
      "Validation samples: 13\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'compile'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 34\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# -------------------------------\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# 7. Build and Compile the Model\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# -------------------------------\u001b[39;00m\n\u001b[0;32m     33\u001b[0m model \u001b[38;5;241m=\u001b[39m unet_model(input_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m*\u001b[39mimage_dim, \u001b[38;5;241m4\u001b[39m))  \u001b[38;5;66;03m# Updated input size\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m(optimizer\u001b[38;5;241m=\u001b[39mAdam(), \n\u001b[0;32m     35\u001b[0m               loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m     36\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, dice_coefficient, iou_metric])\n\u001b[0;32m     37\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# -------------------------------\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# 8. Define Callbacks\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# -------------------------------\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'compile'"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 4. Prepare the Data\n",
    "# -------------------------------\n",
    "\n",
    "# Define the data directory (adjust this path if necessary)\n",
    "data_dir = 'BraTS2020_training_data/content/small_data/'\n",
    "\n",
    "# Get list of .h5 files\n",
    "h5_files = [f for f in os.listdir(data_dir) if f.endswith('.h5')]\n",
    "\n",
    "# Ensure that there are .h5 files in the directory\n",
    "if not h5_files:\n",
    "    raise FileNotFoundError(f\"No .h5 files found in the directory: {data_dir}\")\n",
    "\n",
    "# Split into training and validation sets\n",
    "train_files, val_files = train_test_split(h5_files, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Total samples: {len(h5_files)}\")\n",
    "print(f\"Training samples: {len(train_files)}\")\n",
    "print(f\"Validation samples: {len(val_files)}\")\n",
    "\n",
    "# Parameters\n",
    "batch_size = 8  # Adjust based on GPU memory\n",
    "image_dim = (128, 128)  # Adjust based on your image dimensions\n",
    "\n",
    "X_train, y_train = load_data(train_files, data_dir, image_dim=(128, 128))\n",
    "\n",
    "X_val, y_val = load_data(val_files, data_dir, image_dim=(128, 128))\n",
    "\n",
    "# -------------------------------\n",
    "# 7. Build and Compile the Model\n",
    "# -------------------------------\n",
    "model = unet_model(input_size=(*image_dim, 4))  # Updated input size\n",
    "model.compile(optimizer=Adam(), \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy', dice_coefficient, iou_metric])\n",
    "model.summary()\n",
    "\n",
    "# -------------------------------\n",
    "# 8. Define Callbacks\n",
    "# -------------------------------\n",
    "log_dir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "\n",
    "# TensorBoard callback for visualization\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# EarlyStopping callback with multiple metric monitoring\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=10, \n",
    "    verbose=1, \n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# ModelCheckpoint callback to save the best model with '.keras' extension\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    'model-unet.best.keras',  # Changed from '.h5' to '.keras'\n",
    "    monitor='val_loss', \n",
    "    verbose=1, \n",
    "    save_best_only=True, \n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "# Combine all callbacks\n",
    "callbacks = [\n",
    "    early_stopping,\n",
    "    model_checkpoint,\n",
    "    tensorboard_callback\n",
    "]\n",
    "\n",
    "# -------------------------------\n",
    "# 9. Load the Data\n",
    "# -------------------------------\n",
    "# Assuming you have the DataGenerator instances defined for training and validation\n",
    "# If you're using X_train and y_train, manually fetch the first batch from the generators:\n",
    "\n",
    "# -------------------------------\n",
    "# 10. Train the Model with X_train and y_train\n",
    "# -------------------------------\n",
    "epochs = 3  # You can adjust this based on your requirements\n",
    "\n",
    "try:\n",
    "    results = model.fit(\n",
    "        X_train, y_train,  # Use X_train and y_train directly\n",
    "        validation_data=(X_val, y_val),  # Use X_val and y_val directly\n",
    "        epochs=epochs,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1  # Set to 1 for progress bar, 2 for one line per epoch, 0 for silent\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during training: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1389272-01fa-47a3-9d52-2741cc02baf7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 723383,
     "sourceId": 1267593,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 186512,
     "modelInstanceId": 164165,
     "sourceId": 192524,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 14544.925633,
   "end_time": "2024-12-08T17:03:56.182875",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-12-08T13:01:31.257242",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
